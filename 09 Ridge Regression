### Regression: Ridge

x_range0 = [0.01, 0.1, 1, 10, 100]
train_score_list = []
test_score_list = []

# check ridge scores for different values of alpha

for alpha in x_range0: 
    rid_R = Ridge(alpha)
    rid_R.fit(x_train,y_train)
    train_score_list.append(rid_R.score(x_train,y_train))
    test_score_list.append(rid_R.score(x_test, y_test))
x_range1 = np.linspace(0.001, 1, 100).reshape(-1,1)
x_range2 = np.linspace(1, 10000, 10000).reshape(-1,1)
x_range = np.append(x_range1, x_range2)
coeff = []

# feature response to varying alpha

for alpha in x_range: 
    rid_R = Ridge(alpha)
    rid_R.fit(x_train,y_train)
    coeff.append(rid_R.coef_ )
    
coeff = np.array(coeff)

# plotting Ridge score values and Feature response

fig, ax = plt.subplots(1,2,figsize=(15,5))
x_axis = range(1,20)
for i in range(1, 3):
    plt.subplot(1, 2, i)
    if i == 1:
        plt.plot(x_range0, train_score_list, c = 'g', label = 'Train Score')
        plt.plot(x_range0, test_score_list, c = 'b', label = 'Test Score')
        plt.xscale('log')
        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.4))
        plt.xlabel(r'$\alpha$')
        plt.title('Ridge Score Values')
    if i == 2:
        for i in range(0,9):
            plt.plot(x_range, coeff[:,i], label = 'feature {:d}'.format(i))
        plt.axhline(y=0, xmin=0.001, xmax=9999, linewidth=1, c ='gray')
        plt.xlabel(r'$\alpha$')
        plt.xscale('log')
        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.4), ncol=3, fancybox=True, shadow=True)
        plt.title('Feature Response')
        
### Regression: Ridge: GridSearchCV & Cross Validation

rid_R = Ridge()
params = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}
best_ridR = GridSearchCV(rid_R, params, cv=5)
best_ridR.fit(Xs, Ys)

print('Best Alpha: %.3f' % best_ridR.best_params_['alpha'])
print('Best Score: %.4f' % best_ridR.best_score_)

all_models['Model'].append('Ridge Regression')
all_models['Cross Validation Score'].append(best_ridR.best_score_)
